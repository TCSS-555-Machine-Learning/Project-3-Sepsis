{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Sepsis Prediction</h1>\n",
    "<h4>TCSS 555<br>\n",
    "Spring 2018<br>\n",
    "Thuan Lam, Tood Robbins, Inno Irving Estrera</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current folder is C:\\Thuan\\ML\\Projects\\Sepsis\n",
      "Data\\\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "print('Current folder is {}'.format(cwd))\n",
    "\n",
    "if os.name == \"posix\":\n",
    "    unreadable = set([       \n",
    "        \"NEW_CHARTEVENTS.csv\",\n",
    "        \"ADMISSIONS.csv\",\n",
    "        \"NEW_ICUSTAYS.csv\",\n",
    "        \"DRGCODES.csv\"\n",
    "    ])\n",
    "    USER_DIR = '/Users/innoestrera/Desktop/mimic3/';\n",
    "else:\n",
    "    USER_DIR = 'Data\\\\';\n",
    "print(USER_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "admissions = pd.read_csv(\"{}ADMISSIONS.csv\".format(USER_DIR))[['HADM_ID','SUBJECT_ID']]\n",
    "# convert Diagnosis to binary: 1 means sepsis\n",
    "# admissions['DIAGNOSIS'] = admissions['DIAGNOSIS'].apply(lambda x : 0 if str(x).find('SEPSIS') == -1 else 1)\n",
    "# print(admissions.head(2))\n",
    "# adminssions = shuffle(stays)\n",
    "patients = pd.read_csv(\"{}PATIENTS.csv\".format(USER_DIR))[['SUBJECT_ID','GENDER','DOB']]\n",
    "drugs = pd.read_csv(\"{}DRGCODES.csv\".format(USER_DIR))[['HADM_ID','SUBJECT_ID','DRG_CODE','DESCRIPTION']]\n",
    "\n",
    "stays = pd.read_csv(\"{}NEW_ICUSTAYS.csv\".format(USER_DIR))[['HADM_ID','ICUSTAY_ID','LOS']]\n",
    "# print(stays.head(1))\n",
    "\n",
    "chart = pd.read_csv(\"{}NEW_CHARTEVENTS.csv\".format(USER_DIR))\n",
    "# print(chart.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Y Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a copy with 2 columns only\n",
    "find_sepsis = drugs[['HADM_ID', 'DRG_CODE']].copy()\n",
    "\n",
    "#change drug code 870, 871, 872 to 1; Otherwise, 0\n",
    "#https://www.icd10monitor.com/understanding-sepsis-an-example-of-the-convergence-of-clinical-quality-coding-reimbursement-and-audit\n",
    "find_sepsis['DRG_CODE'] = find_sepsis['DRG_CODE'].apply(lambda x: 1 if (x >= 870 and x <= 872) or (x >= 867 and x <= 869) or x == 776 or (x >= 974 and x <= 976) else 0)\n",
    "\n",
    "#sum all drugcodes grouup by HADM_ID. If the sum > 0 means HADM_ID has/had sepsis\n",
    "find_sepsis = find_sepsis.groupby(['HADM_ID']).sum().reset_index() # .sort_values(by=['DRG_CODE'], ascending=False)\n",
    "\n",
    "#convert DRG_CODE to binary: 1 means sepsis, 0 means NO\n",
    "find_sepsis['DRG_CODE'] = find_sepsis['DRG_CODE'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "#change DRG_CODR to SEPSIS, it would be easier \n",
    "find_sepsis.rename(columns={'DRG_CODE': 'SEPSIS'}, inplace=True)\n",
    "\n",
    "# print('find_sepsis: ')\n",
    "# print(find_sepsis.head(2))\n",
    "# print('admission1: ')\n",
    "# print(admissions.head(2))\n",
    "\n",
    "#merge tables to create the Y set\n",
    "admissions = pd.merge(admissions, find_sepsis, on='HADM_ID', how='left') #.drop(['SUBJECT_ID'], axis=1)\n",
    "admissions = admissions.fillna(0)\n",
    "# print('admission2: ')\n",
    "# print(admissions.head(2))\n",
    "\n",
    "# admissions.loc[admissions['SEPSIS'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the X Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3>Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.merge(admissions, stays, on='HADM_ID', how='inner') #.drop(['SUBJECT_ID'], axis=1)\n",
    "# print(master.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3>Get ItemIDs from ChartEvents then Add into Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get itemsIds from ChartEvent\n",
    "for x in chart.ITEMID.unique():\n",
    "    master[x] = 0\n",
    "\n",
    "# set index\n",
    "master = master.set_index('ICUSTAY_ID')\n",
    "# print(master.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3>Put Item's Values into Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in chart.iterrows():    \n",
    "    master.loc[row['ICUSTAY_ID'], row['ITEMID']] = row['VALUE']\n",
    "# print(master.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3>Add Paitien Info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Patients table\n",
    "patients['AGE'] = patients['DOB'].apply(lambda x: x[:4])\n",
    "maxYear = int(patients['AGE'].max())\n",
    "\n",
    "patients['AGE'] = patients['AGE'].apply(lambda x: maxYear - int(x))\n",
    "patients['GENDER'] = patients['GENDER'].apply(lambda x: 0 if x == 'F' else 1)\n",
    "patients = patients.drop(['DOB'], axis=1)\n",
    "\n",
    "# add Patients into Master\n",
    "master = pd.merge(master, patients, on='SUBJECT_ID', how='inner').drop(['SUBJECT_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3>Analyze Gender and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_only = master[master['SEPSIS']==1]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15,15))\n",
    "fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "fig.set_size_inches(20, 10)\n",
    "plt.subplots_adjust(wspace=1, hspace=1)\n",
    "\n",
    "# Gender\n",
    "g = sepsis_only.groupby(['GENDER']).size().reset_index(name='GENDER_SEPSIS_COUNTS')\n",
    "g['GENDER_COUNTS'] = master.groupby(['GENDER']).size().reset_index(name='GENDER_COUNTS')['GENDER_COUNTS']\n",
    "g['GENDER_PERCENT'] = g.apply(lambda row: row.GENDER_SEPSIS_COUNTS / row.GENDER_COUNTS * 100, axis=1)\n",
    "g = g.drop(columns=['GENDER_SEPSIS_COUNTS','GENDER_COUNTS'])\n",
    "g.iloc[0, g.columns.get_loc('GENDER')] = 'Female'\n",
    "g.iloc[1, g.columns.get_loc('GENDER')] = 'Male'\n",
    "g = g.set_index('GENDER')\n",
    "g.plot.bar(subplots=True, legend=None, ax=axes[0,0], rot=0, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "b1 = sepsis_only.groupby(['AGE']).size().reset_index(name='AGE_SEPSIS_COUNTS')\n",
    "b2 = master.groupby(['AGE']).size().reset_index(name='AGE_COUNTS')\n",
    "# show all records from master\n",
    "b = pd.merge(b1, b2, on='AGE', how='right').fillna(0)\n",
    "b['AGE_PERCENT'] = b.apply(lambda row: row.AGE_SEPSIS_COUNTS / row.AGE_COUNTS * 100, axis=1)\n",
    "b = b.drop(columns=['AGE_SEPSIS_COUNTS','AGE_COUNTS'])\n",
    "b = b.set_index('AGE')\n",
    "b.plot.bar(legend=None, rot=0, figsize=(15,10), fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3>Convert Age to Age_Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.reset_index()\n",
    "arr = []\n",
    "for i in range(1000):\n",
    "    arr.append(0)\n",
    "\n",
    "for index, row in b.iterrows():\n",
    "    age = int(row['AGE'])\n",
    "    \n",
    "    percent = row['AGE_PERCENT'] \n",
    "    print('age: {}  {}%'.format(age, percent))\n",
    "    if percent < 3:\n",
    "        arr[age] = 0\n",
    "    elif percent < 6:\n",
    "        arr[age] = 1\n",
    "    elif percent < 9:\n",
    "        arr[age] = 2\n",
    "    elif percent < 12:\n",
    "        arr[age] = 3\n",
    "    elif percent < 15:\n",
    "        arr[age] = 4\n",
    "    else:    \n",
    "        arr[age] = 5\n",
    "        \n",
    "master['AGE'] = master['AGE'].apply(lambda x : arr[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3>Finalize the Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the SEPSIS column to the last \n",
    "cols = master.columns.tolist()\n",
    "cols.insert(len(master.columns) - 1, cols.pop(cols.index('SEPSIS')))\n",
    "master = master.reindex(columns= cols).reset_index()\n",
    "\n",
    "# remove unnecessary columns\n",
    "master.drop(['HADM_ID'], axis=1, inplace=True)\n",
    "# print(master.head(2))\n",
    "print('Master built. Shape: {}'.format(master.shape))\n",
    "print(master.columns.values)\n",
    "\n",
    "master.fillna(0, inplace=True)\n",
    "master = shuffle(master)\n",
    "# master = master[:30000]\n",
    "\n",
    "# checking null\n",
    "# ol_mask=master.isnull().any(axis=0) \n",
    "# ol_mask\n",
    "\n",
    "if 'index' in master.columns:\n",
    "    master.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepsis_only = master[master['SEPSIS']==1]\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15,15))\n",
    "# fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "# fig.set_size_inches(20, 10)\n",
    "# plt.subplots_adjust(wspace=1, hspace=1)\n",
    "\n",
    "# # Gender\n",
    "# g = sepsis_only.groupby(['SEPSIS']).size().reset_index(name='sepsis_counts')\n",
    "# g['total_stays'] = master.groupby(['SEPSIS']).size().reset_index(name='total_stays')['total_stays']\n",
    "# g['sepsis_percent'] = g.apply(lambda row: row.sepsis_counts / row.total_stays * 100, axis=1)\n",
    "# g\n",
    "# # g = g.drop(columns=['sepsis_counts','total_stays'])\n",
    "# # g.iloc[0, g.columns.get_loc('SEPSIS')] = 'No Sepsis'\n",
    "# # g.iloc[1, g.columns.get_loc('SEPSIS')] = 'Sepsis'\n",
    "# # g = g.set_index('gender')\n",
    "# # g.plot.bar(subplots=True, legend=None, ax=axes[0,0], rot=0, fontsize=12)\n",
    "\n",
    "all_rows = master.shape[0]\n",
    "sepsis_rows = len(master[(master['SEPSIS'] == 1)])\n",
    "baseline = 1 -(sepsis_rows / all_rows)\n",
    "print('Sepsis: {} rows out of {} rows'.format(sepsis_rows, all_rows))\n",
    "print('Baseline: {}'.format(baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "col = len(master.columns) - 1\n",
    "array = master.values   #numpy array\n",
    "X = array[:,0:col]# first N columns\n",
    "Y = array[:,col]  # SEPSIS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "# print('{}'.format(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "\n",
    "messages = []\n",
    "matrices = []\n",
    "for name, model in models:\n",
    "    model.fit(X_train, Y_train)\n",
    "    prediction = model.predict(X_validation)\n",
    "    \n",
    "    accuracyScore = accuracy_score(Y_validation, prediction)\n",
    "    confusionMatrix = confusion_matrix(Y_validation, prediction)\n",
    "    matrices.append(confusionMatrix)\n",
    "\n",
    "print(messages)\n",
    "print(matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> bla bla bla. <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "# lr = LogisticRegression()\n",
    "# lr.fit(X_train, Y_train)\n",
    "# predictions = lr.predict(X_validation)\n",
    "print(predictions)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "predictions = rf.predict(X_validation)\n",
    "# lr = LogisticRegression()\n",
    "# lr.fit(X_train, Y_train)\n",
    "# predictions = lr.predict(X_validation)\n",
    "print(predictions)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "messages = []\n",
    "matrices = []\n",
    "for name, model in models:\n",
    "    model.fit(X_train, Y_train)\n",
    "    prediction = model.predict(X_validation)\n",
    "    \n",
    "    accuracyScore = accuracy_score(Y_validation, prediction)\n",
    "    confusionMatrix = confusion_matrix(Y_validation, prediction)\n",
    "    classificationReport = classification_report(Y_validation, prediction)\n",
    "    precision, recall, thresholds = precision_recall_curve(Y_validation, prediction)\n",
    "    sensitivity = confusionMatrix[0, 0]/(confusionMatrix[0, 0]+confusionMatrix[0, 1])\n",
    "    specificity = confusionMatrix[1, 1]/(confusionMatrix[1, 0]+confusionMatrix[1, 1])\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_validation, prediction)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    #metrics.roc_curve(Y_validation, prediction)\n",
    "    #auc = metrics.auc(confusionMatrix[0, 0], confusionMatrix[1, 1])\n",
    "    \n",
    "    print(\"accuracy\", accuracyScore)\n",
    "    print(\"confusion Matrix\", confusionMatrix)\n",
    "    print(\"precision\", precision)\n",
    "    print(\"recall\", recall)\n",
    "    print(\"sensitivity\", sensitivity)\n",
    "    print(\"specificity\", specificity)\n",
    "    print(\"stuff\", roc_curve(Y_validation, prediction))\n",
    "    plt.title('AUC')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    #matrices.append(confusionMatrix)\n",
    "    \n",
    "#print(confusionMatrix)\n",
    "#print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
